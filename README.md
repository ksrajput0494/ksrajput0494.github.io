# Software Engineer|Data Engineer

## Technical Skills :
-	Operating System:&nbsp;&nbsp;Windows Family, LINUX
-	Programming Languages:&nbsp;Java, Python, pyspark, sparksql
-	RDBMS:&nbsp;&nbsp;&nbsp;Oracle, MSSQL
-	Platforms:&nbsp;&nbsp;&nbsp;Kafka
-	Git Hub:&nbsp;&nbsp;&nbsp;Bitbucket, Github
-	Amazon Web Service:&nbsp;S3, EC2, Lambda
-	Azure:&nbsp;&nbsp;&nbsp;Azure Key Vault, Azure Data Factory, Azure DataBricks
-	Enterprise Applications:&nbsp;Informatica MDM 10.X, Informatica MDM Saas, Reference 360, CDI, CDQ
-	Others:&nbsp;&nbsp;&nbsp;Data Structures and Algorithms, System Design
-	Soft Skills:&nbsp;&nbsp;&nbsp;Strong Problem Solving, Fast Learner, Excellent communication, Team work and                 
  				collaboration
 	
## Education
-	Bachelors, Computer Science and Engineering from MAIET College affiliated to RTU, Jaipur, India

## Work Experience
- LumenData Pvt Ltd Bangalore: - Jun 2017 – Oct 2021
Work summary
- Edwards Life Science Kuala Lumpur Malaysia: -Oct 2021 – June 2022
Work summary
- Informatica – June 2022 – Present

## Mock Projects:

### Formula 1:
#### Project Description: Mock project for assessing, analyzing, cleansing initial and incremental loads of data using csv files into databricks.
#### Git Hub Link : - [Formula1](https://github.com/ksrajput0494/DataBricks_Formula1/tree/main/Formula1/Formula1)
#### Responsibilities: -
-	Created Azure datalake with 3 folders Raw, Processed and Presentation.
-	Files will be stored in Raw folder in date wise folder format.
-	Created multiple Pyspark notebook along with notebook workflow for ingesting data from Azure datalake raw layer with into processed layer.
-	Developed cleanse like adding ingestion date, Source system data, column name changes etc.
-	Create pyspark notebook to process the data in processed layer and create views to export them to presentation layer. 
-	Created multiple tables on top of backend file using delta.
-	Provided logics to differentiate and overwrite delta records by portioning logics.


#####  Projects:

### Nissan
#### Domain: - Customer
#### Project Description: - To implement MDM Solution for maintaining existing and prospective Nissan Customers.
#### Responsibilities: -
-	Creating Lambda to extract data from S3 bucket and load it into snowflake table
-	Configured snowflake connector in AWS Lambda
-	Configured Mapping between S3 files from different system to Snowflake tables
-	Worked with solution architect for building High level designs and models for Nissan’s implementation.
-	Do unit testing by providing sample inputs to lambda functions.
-	Debug the code for implementation and production related issues.


### Franklin Templeton
#### Domain: Investment
#### Project Description: Client wanted to move from Trillium to a custom python based solution which can differentiate between Person Name and Company Name along with locate tool for address cleansing. 
#### Responsibilities:
-	Created a custom code to fetch person Name and Company name from an address line
-	Importing and exporting data in fixed width format.
-	Created a manual queue for data steward activity.
-	Created Logs for the program.
-	Created a Patterns for the program to understand line and recode them accordingly.
-	Created code to convert an address line to pattern.
-	Created the logic to classify address line.
-	Created binary search program to find elements for pattern making.
-	Created a Multiprocessing program and Scheduler program.
-	Created program to transfer file from landing directory to staging directory while under processing.
-	After processing delete the file from landing, staging directories and save it in archive directory. 
-	Prepared unit test cases for Program.
-	Debug and created testing utilities to debug the code for undesired outputs and implementation related issues. 


### Charter Communication:
#### Domain: Telecom
#### Project Description: To create an real-time integration system to manage prospective and existing customers.
#### Responsibilities: -
-	Created Java program to load data into Kafka from data base and web service.
-	Created Java program to load a data form a topic then transform data and Load to another topic.  
-	Created java program to load the data from Kafka topic and store it in IDQ database or send it to IDQ web services.
-	Troubleshooting and fixing issues with inbound integrations.

### Meta
####  Domain: - Customer
####  Project Description: - Java based validation and hierarchy management  via user exits implementation. 
####  Responsibilities: -
-	Created Implementation documents.
-	Implemented Get, Add Relationship, remove relationship related sif api call in user exit.
-	Implemented post merge User exit.
-	Worked on code optimization and sif related custom implementation.
-	Created build.xml to create user exits with all necessary files.
-	Created custom test suit to test sif call on local system before implementing in user exit.
-	Debug the code for implementation and production related issues.
-	Provided support for postproduction go live.

### C360 for LifeScience
####  Domain: Life Science
####  Project Description: Product development for Informatica C360 for Life Science. Having a fully implemented Life Science domain solution extensions for clients.
####  Responsibilities:
-	Created HighCharts including drill down code.
-	Created a custom code to fetch data to represent in HighCharts. 
-	Created Business Entities and Business Entities View.
-	Created Layouts and Custom java script code to represent MDM data in Dashboard UI.
-	Created Queries and Packages.
-	Created and configured relationships. 
-	Created Custom cleanse transformations. 
-	Configured triggers and tasks.
-	Configured Reference Entities for creating relationships in UI. 
-	Configures Relationship entities in Provisioning for HighCharts.
-	Configured UI based custom errors.
-	Configured UI codes as per modifications in Business Entity.


### AAIS
####  Domain: Insurance
####  Project Description: To implement MDM solution for maintaining existing and prospective customer.
####  Responsibilities:
-	Analyze specification provided by Client to develop Modular design documents.
-	Conversions to adopt new functionalities available in Enterprise Service module
-	Creating entities and relations to design the model
-	Creating Collections and Forms to define how records appear
-	Creating Steppers, Action sets to author data using collections and forms
-	Creating Workflows to assign multiple roles to multiple users
-	Building UI application for business users to create, edit and delete records.

### Cummins
####  Domain: - Supplier
####  Project Description: - To implement MDM Solution for maintaining existing and prospective suppliers.
####  Responsibilities:
-	Creating Low Level implementation design document for UI
-	Worked with solution architect for building High level designs and models.
-	Developing Business entities, relations, references, View and transformation in provisioning
-	Developing UI Layout and javascript enhancements
-	Created triggers, task templets to configure ActiveVos and create/update functionality of Business Entity.
-	Configuring ActiveVos workflow in provisioning on multiple roles.
-	Configuring DAAS, WSDL and SOAP based web services integration on provisioning
-	Created multiple Cleanse Functions required for UI validations.
-	Created and configured match rules for showing duplicate records in UI
-	Worked on migration from Dev to qa, uat and prod.
-	Configured IDQ web services in cleanse function.
-	Used Sif calls to perform different operations
-	Worked on Message Queue/trigger configurations
-	Developed multiple application for different use cases of UI
-	Developed User Exits for post load requirements

### Edwards LifeScience
####  Domain: - Customer,Supplier,Product
####  Project Description: - To implement MDM Solution for maintaining existing customer, supplier and product information to make sure no redundant and duplicate records are present in database or downstream systems. For    product information has to be managed for analytical need for company. 
####  Responsibilities:
-	Created HLD and LLD document
-	POC on custom UI created on reactjs to integrate with informatica MDM along with creating and updating existing records using the UI along with other features.
-	Development on provisioning tool for Customer related features.
-	Development on provisioning tool for supplier related features.
-	Mentoring junior resources on developed and troubleshooting bugs.

### WTW Grass Savoye
####  Domain: - Customer
####  Project Description: - To migrate existing on prem solution to Informatica MDM Saas enviroment. 
####  Responsibilities:
-	Created HLD and LLD document.
-	Created custom entities and extended existing Person and Organization entities.
-	Created layouts and updating c360 application for newly created layouts.
-	Created new roles and set privileges for entities.
-	Created custom source systems.
-	Created DQ rule specification on entities.
-	Created Reference entities and tables in Reference 360 models
-	Created ingress and egress jobs
-	Created cross walks for downstream systems consumption.
-	Troubleshooting bugs related to changes in on prem and Saas version of MDM.
-	Redesigning solution to implement same functionality in saas as in on prem.
-	Provided Demos and PPT presentation on implementations.
-	Worked on client training and handover activities.

### Candian Pacific Railway
####  Domain: - Multidomain MDM Saas
####  Project Description: - To implement MDM Solution for maintaining train and track related information in cloud solution. 
####  Responsibilities:
-	Created HLD and LLD document
-	Developed Entities, Record Layout, application, roles rules, egress and ingress jobs
-	Developed custom Reference tables and relationship model for R360 and implemented in Custom entities.
-	Developed ingress and egress jobs to be used for importing R360 entities.

### European Medical Agency
####  Domain: - Multidomain MDM (Medicine and Product)
####  Project Description: - Enhancement of existing MDM Solution maintaining for realtime UI applications.
####  Responsibilities:
-	Created HLD and LLD document
-	Implemented Rest api call to work parallelly with FHIR protocol
-	Created Post load, Post Match and Post merge user exit code for client implementation.
-	Implemented sif call in user exits for client use cases.
-	Developed IDD User exit code for custom validation errors and enrichment of fields.
-	Worked in bitbucket for uploading latest user exit code and Hub console changes to be migrated to higher environments.
-	Work on IDD to develop sections and DQ validations.
-	Worked on provisioning for implementing Rest put call function used by different downstream applications



### Unilever
####  Domain: - Upgrade and Installation
####  Project Description: - In place upgrade form 10.4HF1 to 10.5GA in Dev, SIT, UAT, Pre Prod and Production environment in over 60 servers. 

-	Created Implementation documents.
-	Installed New version of Java Zulu removing earlier Java.
-	Installed Jboss, Hub, Process server, Elastic search and activevos.
-	Configured properties in standalone-full, standalone-conf, roles, roles.mapping, build.properties, ElasticSearch etc.
-	Replaced older version password in cmx_system along with other ors and admins.
-	Upgraded master and ors.
-	Active MQ configuration, Infini span configuration and cmx-server configuration for multinode cluster
-	SSL configuration 
-	Configured activevos clusters
-	Configured elasticsearch multinode cluster along with master slave configuration.
-	Configured HA database.
-	Debug for deployment and installation issues and rectify system related issues.
-	Lead the team of 4 developer and provided guidance to Installation, deployment, and test.


### Vodafone Ziggo UK
####  Domain: - Customer 360
####  Project Description: - POV for showing business values buy combining data from multiple source systems and deduplicating data across systems. 
####  Responsibilities:
-	Created Implementation documents.
-	Created ETL Mapping documents.
-	Create reference entity/ Lov documents for all entities
-	Configured Data models along with reference entities.
-	Created Ingress and egress MDM jobs
-	Created Mappings/ data pipelines to take data from source system cleans it enrich it and put it in target system.
-	Created Mappings/ data pipelines to take data from MDM and put it in snowflake tables.
-	Implemented Hierarchy and relationships.
-	Configured match and merge rules.
-	Configured UI for data stewardship.
-	Configured Manual merge tasks to show tasks in UI for data stewards to approve.
-	Configured Survivorship rules for the attributes and source systems




[Formula1](https://github.com/ksrajput0494/DataBricks_Formula1/tree/main/Formula1/Formula1)

![EEG Band Discovery](/assets/img)
